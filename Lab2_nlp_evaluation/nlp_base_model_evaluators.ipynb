{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate with quantitative NLP evaluators\n",
    "\n",
    "## Objective\n",
    "This notebook demonstrates how to use NLP-based evaluators to assess the quality of generated text by comparing it to reference text. By the end of this tutorial, you'll be able to:\n",
    " - Understand different NLP evaluators such as `BleuScoreEvaluator`, `GleuScoreEvaluator`, `MeteorScoreEvaluator`, and `RougeScoreEvaluator`.\n",
    " - Evaluate dataset using these evaluators.\n",
    "\n",
    "## Time\n",
    "You should expect to spend about 10 minutes running this notebook.\n",
    "\n",
    "## Before you begin\n",
    "\n",
    "### Installation\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1733832648838
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-evaluation in /opt/conda/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (2.8.0)\n",
      "Requirement already satisfied: azure-identity>=1.16.0 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (1.25.1)\n",
      "Requirement already satisfied: azure-core>=1.30.2 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (1.36.0)\n",
      "Requirement already satisfied: nltk>=3.9.1 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (3.9.1)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (12.19.0)\n",
      "Requirement already satisfied: httpx>=0.25.1 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (0.28.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.2 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (2.2.2)\n",
      "Requirement already satisfied: openai>=1.108.0 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (2.5.0)\n",
      "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (0.18.6)\n",
      "Requirement already satisfied: msrest>=0.6.21 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (0.7.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.6 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (3.1.6)\n",
      "Requirement already satisfied: aiohttp>=3.0 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.18.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.12/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (4.15.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.12/site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (44.0.1)\n",
      "Requirement already satisfied: msal>=1.30.0 in /opt/conda/lib/python3.12/site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.34.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.3.1)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /opt/conda/lib/python3.12/site-packages (from azure-storage-blob>=12.10.0->azure-ai-evaluation) (0.7.2)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (2.8.0)\n",
      "Requirement already satisfied: azure-identity>=1.16.0 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (1.25.1)\n",
      "Requirement already satisfied: azure-core>=1.30.2 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (1.36.0)\n",
      "Requirement already satisfied: nltk>=3.9.1 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (3.9.1)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (12.19.0)\n",
      "Requirement already satisfied: httpx>=0.25.1 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (0.28.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.2 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (2.2.2)\n",
      "Requirement already satisfied: openai>=1.108.0 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (2.5.0)\n",
      "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (0.18.6)\n",
      "Requirement already satisfied: msrest>=0.6.21 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (0.7.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.6 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (3.1.6)\n",
      "Requirement already satisfied: aiohttp>=3.0 in /opt/conda/lib/python3.12/site-packages (from azure-ai-evaluation) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.18.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.12/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (4.15.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.12/site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (44.0.1)\n",
      "Requirement already satisfied: msal>=1.30.0 in /opt/conda/lib/python3.12/site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.34.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.3.1)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /opt/conda/lib/python3.12/site-packages (from azure-storage-blob>=12.10.0->azure-ai-evaluation) (0.7.2)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.1->azure-ai-evaluation) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from Jinja2>=3.1.6->azure-ai-evaluation) (2.1.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /opt/conda/lib/python3.12/site-packages (from msrest>=0.6.21->azure-ai-evaluation) (2.0.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.12/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (4.66.5)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from openai>=1.108.0->azure-ai-evaluation) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/conda/lib/python3.12/site-packages (from openai>=1.108.0->azure-ai-evaluation) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from openai>=1.108.0->azure-ai-evaluation) (2.12.3)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from openai>=1.108.0->azure-ai-evaluation) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2023.3)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.12/site-packages (from ruamel.yaml<1.0.0,>=0.17.10->azure-ai-evaluation) (0.2.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (1.17.1)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.25.1->azure-ai-evaluation) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from Jinja2>=3.1.6->azure-ai-evaluation) (2.1.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /opt/conda/lib/python3.12/site-packages (from msrest>=0.6.21->azure-ai-evaluation) (2.0.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.12/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (4.66.5)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from openai>=1.108.0->azure-ai-evaluation) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/conda/lib/python3.12/site-packages (from openai>=1.108.0->azure-ai-evaluation) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from openai>=1.108.0->azure-ai-evaluation) (2.12.3)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from openai>=1.108.0->azure-ai-evaluation) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2023.3)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.12/site-packages (from ruamel.yaml<1.0.0,>=0.17.10->azure-ai-evaluation) (0.2.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.12/site-packages (from cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (1.17.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.108.0->azure-ai-evaluation) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.108.0->azure-ai-evaluation) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.108.0->azure-ai-evaluation) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (2.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.12/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-evaluation) (3.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.108.0->azure-ai-evaluation) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.108.0->azure-ai-evaluation) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai>=1.108.0->azure-ai-evaluation) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (2.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.12/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-evaluation) (3.3.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (2.21)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the packages\n",
    "%pip install azure-ai-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1733832651097
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.credentials.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure AI project and Azure OpenAI conncetion with your environment variables\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"AZURE_RESOURCE_GROUP\"),\n",
    "    \"project_name\": os.environ.get(\"AZURE_PROJECT_NAME\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up env vars for model endpoints and keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_var = { \n",
    "    \"gpt-35-turbo\": {\n",
    "        \"endpoint\": os.environ.get(\"AZURE_OPENAI_GPT35_ENDPOINT\"),\n",
    "        \"key\": os.environ.get(\"AZURE_OPENAI_GPT35_API_KEY\"),\n",
    "    },\n",
    "    \"gpt-4\": {\n",
    "        \"endpoint\": os.environ.get(\"AZURE_OPENAI_GPT4_ENDPOINT\"),\n",
    "        \"key\": os.environ.get(\"AZURE_OPENAI_GPT4_API_KEY\"),\n",
    "    },\n",
    "    \"gpt-4o\": {\n",
    "        \"endpoint\": os.environ.get(\"AZURE_OPENAI_GPT4o_ENDPOINT\"),\n",
    "        \"key\": os.environ.get(\"AZURE_OPENAI_GPT4o_API_KEY\"),\n",
    "    },\n",
    "   \"gpt-4o-mini\" : { \n",
    "        \"endpoint\" : os.environ.get(\"AZURE_OPENAI_GPT4o-mini_ENDPOINT\"), \n",
    "        \"key\" : os.environ.get(\"AZURE_OPENAI_GPT4o-mini_API_KEY\"), \n",
    "    },    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import requests\n",
      "from typing_extensions import Self\n",
      "from typing import TypedDict\n",
      "from promptflow.tracing import trace\n",
      "\n",
      "\n",
      "class ModelEndpoints:\n",
      "    def __init__(self: Self, env: dict, model_type: str) -> str:\n",
      "        self.env = env\n",
      "        self.model_type = model_type\n",
      "\n",
      "    class Response(TypedDict):\n",
      "        query: str\n",
      "        response: str\n",
      "\n",
      "    @trace\n",
      "    def __call__(self: Self, query: str) -> Response:\n",
      "        if self.model_type == \"gpt-4\":\n",
      "            output = self.call_gpt4_endpoint(query)\n",
      "        elif self.model_type == \"gpt-35-turbo\":\n",
      "            output = self.call_gpt35_turbo_endpoint(query)\n",
      "        elif self.model_type == \"gpt-4o\":\n",
      "            output = self.call_gpt4o_endpoint(query)\n",
      "        elif self.model_type == \"gpt-4o-mini\":\n",
      "            output = self.call_gpt4o_mini_endpoint(query)\n",
      "        else:\n",
      "            output = self.call_default_endpoint(query)\n",
      "\n",
      "        return output\n",
      "\n",
      "    def query(self: Self, endpoint: str, headers: str, payload: str) -> str:\n",
      "        response = requests.post(url=endpoint, headers=headers, json=payload)\n",
      "        return response.json()\n",
      "\n",
      "    def call_gpt4_endpoint(self: Self, query: str) -> Response:\n",
      "        endpoint = self.env[\"gpt-4\"][\"endpoint\"]\n",
      "        key = self.env[\"gpt-4\"][\"key\"]\n",
      "\n",
      "        headers = {\"Content-Type\": \"application/json\", \"api-key\": key}\n",
      "\n",
      "        payload = {\"messages\": [{\"role\": \"user\", \"content\": query}], \"max_tokens\": 500}\n",
      "\n",
      "        output = self.query(endpoint=endpoint, headers=headers, payload=payload)\n",
      "        response = output[\"choices\"][0][\"message\"][\"content\"]\n",
      "        return {\"query\": query, \"response\": response}\n",
      "\n",
      "    def call_gpt35_turbo_endpoint(self: Self, query: str) -> Response:\n",
      "        endpoint = self.env[\"gpt-35-turbo\"][\"endpoint\"]\n",
      "        key = self.env[\"gpt-35-turbo\"][\"key\"]\n",
      "\n",
      "        headers = {\"Content-Type\": \"application/json\", \"api-key\": key}\n",
      "\n",
      "        payload = {\"messages\": [{\"role\": \"user\", \"content\": query}], \"max_tokens\": 500}\n",
      "\n",
      "        output = self.query(endpoint=endpoint, headers=headers, payload=payload)\n",
      "        response = output[\"choices\"][0][\"message\"][\"content\"]\n",
      "        return {\"query\": query, \"response\": response}\n",
      "\n",
      "    def call_gpt4o_endpoint(self: Self, query: str) -> Response:\n",
      "        endpoint = self.env[\"gpt-4o\"][\"endpoint\"]\n",
      "        key = self.env[\"gpt-4o\"][\"key\"]\n",
      "\n",
      "        headers = {\"Content-Type\": \"application/json\", \"api-key\": key}\n",
      "\n",
      "        payload = {\"messages\": [{\"role\": \"user\", \"content\": query}], \"max_tokens\": 500}\n",
      "\n",
      "        output = self.query(endpoint=endpoint, headers=headers, payload=payload)\n",
      "        response = output[\"choices\"][0][\"message\"][\"content\"]\n",
      "        return {\"query\": query, \"response\": response}\n",
      "    \n",
      "    def call_gpt4o_mini_endpoint(self: Self, query: str) -> Response:\n",
      "        endpoint = self.env[\"gpt-4o-mini\"][\"endpoint\"]\n",
      "        key = self.env[\"gpt-4o-mini\"][\"key\"]\n",
      "\n",
      "        headers = {\"Content-Type\": \"application/json\", \"api-key\": key}\n",
      "\n",
      "        payload = {\"messages\": [{\"role\": \"user\", \"content\": query}], \"max_tokens\": 500}\n",
      "\n",
      "        output = self.query(endpoint=endpoint, headers=headers, payload=payload)\n",
      "        response = output[\"choices\"][0][\"message\"][\"content\"]\n",
      "        return {\"query\": query, \"response\": response}\n",
      "\n",
      "\n",
      "    def call_default_endpoint(query: str) -> Response:\n",
      "        return {\"query\": \"What is the capital of United Kingdom?\", \"response\": \"London\"}\n"
     ]
    }
   ],
   "source": [
    "with open(\"target_nlp_api/target_nlp_api.py\") as fin:\n",
    "    print(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from target_nlp_api.target_nlp_api import ModelEndpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1733832746096
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Evaluating NLP metrics -  gpt-35-turbo\n",
      "-----------------------------------\n",
      "2025-10-21 08:42:39 +0000 140016922646208 execution.bulk     INFO     Finished 1 / 4 lines.\n",
      "2025-10-21 08:42:39 +0000 140016922646208 execution.bulk     INFO     Average execution time for completed lines: 0.9 seconds. Estimated time for incomplete lines: 2.7 seconds.\n",
      "2025-10-21 08:42:39 +0000 140016922646208 execution.bulk     INFO     Finished 1 / 4 lines.\n",
      "2025-10-21 08:42:39 +0000 140016922646208 execution.bulk     INFO     Average execution time for completed lines: 0.9 seconds. Estimated time for incomplete lines: 2.7 seconds.\n",
      "2025-10-21 08:42:39 +0000 140016922646208 execution.bulk     INFO     Finished 2 / 4 lines.\n",
      "2025-10-21 08:42:39 +0000 140016922646208 execution.bulk     INFO     Average execution time for completed lines: 0.51 seconds. Estimated time for incomplete lines: 1.02 seconds.\n",
      "2025-10-21 08:42:39 +0000 140016922646208 execution.bulk     INFO     Finished 2 / 4 lines.\n",
      "2025-10-21 08:42:39 +0000 140016922646208 execution.bulk     INFO     Average execution time for completed lines: 0.51 seconds. Estimated time for incomplete lines: 1.02 seconds.\n",
      "2025-10-21 08:42:40 +0000 140016922646208 execution.bulk     INFO     Finished 3 / 4 lines.\n",
      "2025-10-21 08:42:40 +0000 140016922646208 execution.bulk     INFO     Average execution time for completed lines: 0.57 seconds. Estimated time for incomplete lines: 0.57 seconds.\n",
      "2025-10-21 08:42:40 +0000 140016922646208 execution.bulk     INFO     Finished 3 / 4 lines.\n",
      "2025-10-21 08:42:40 +0000 140016922646208 execution.bulk     INFO     Average execution time for completed lines: 0.57 seconds. Estimated time for incomplete lines: 0.57 seconds.\n",
      "2025-10-21 08:42:41 +0000 140016922646208 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-10-21 08:42:41 +0000 140016922646208 execution.bulk     INFO     Average execution time for completed lines: 0.56 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-10-21 08:42:41 +0000 140016922646208 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-10-21 08:42:41 +0000 140016922646208 execution.bulk     INFO     Average execution time for completed lines: 0.56 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"TARGET_20251021_084238_910183\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-21 08:42:38.910183+00:00\"\n",
      "Duration: \"0:00:03.005169\"\n",
      "\n",
      "2025-10-21 08:42:41 +0000 140016904812224 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"TARGET_20251021_084238_910183\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-21 08:42:38.910183+00:00\"\n",
      "Duration: \"0:00:03.005169\"\n",
      "\n",
      "2025-10-21 08:42:41 +0000 140016904812224 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-10-21 08:42:42 +0000 140016904812224 execution.bulk     INFO     Average execution time for completed lines: 0.0 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-10-21 08:42:42 +0000 140016904812224 execution.bulk     INFO     Average execution time for completed lines: 0.0 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-10-21 08:42:42 +0000 140016914253504 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-10-21 08:42:42 +0000 140016914253504 execution.bulk     INFO     Average execution time for completed lines: 0.11 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-10-21 08:42:42 +0000 140016888026816 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-10-21 08:42:42 +0000 140016914253504 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-10-21 08:42:42 +0000 140016914253504 execution.bulk     INFO     Average execution time for completed lines: 0.11 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-10-21 08:42:42 +0000 140016888026816 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-10-21 08:42:42 +0000 140016888026816 execution.bulk     INFO     Average execution time for completed lines: 0.12 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-10-21 08:42:42 +0000 140016888026816 execution.bulk     INFO     Average execution time for completed lines: 0.12 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n",
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n",
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"gleu_20251021_084241_942989\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-21 08:42:41.942989+00:00\"\n",
      "Duration: \"0:00:01.008575\"\n",
      "\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"bleu_20251021_084241_946498\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-21 08:42:41.946498+00:00\"\n",
      "Duration: \"0:00:01.011501\"\n",
      "\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"rouge_20251021_084241_956636\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-21 08:42:41.956636+00:00\"\n",
      "Duration: \"0:00:01.029718\"\n",
      "\n",
      "2025-10-21 08:42:45 +0000 140016896419520 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-10-21 08:42:45 +0000 140016896419520 execution.bulk     INFO     Average execution time for completed lines: 0.85 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-10-21 08:42:45 +0000 140016896419520 execution.bulk     INFO     Finished 4 / 4 lines.\n",
      "2025-10-21 08:42:45 +0000 140016896419520 execution.bulk     INFO     Average execution time for completed lines: 0.85 seconds. Estimated time for incomplete lines: 0.0 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n",
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n",
      "Aggregated metrics for evaluator is not a dictionary will not be logged as metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"meteor_20251021_084241_965495\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-10-21 08:42:41.965495+00:00\"\n",
      "Duration: \"0:00:03.413234\"\n",
      "\n",
      "======= Combined Run Summary (Per Evaluator) =======\n",
      "\n",
      "{\n",
      "    \"bleu\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:01.011501\",\n",
      "        \"completed_lines\": 4,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    },\n",
      "    \"gleu\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:01.008575\",\n",
      "        \"completed_lines\": 4,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    },\n",
      "    \"meteor\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:03.413234\",\n",
      "        \"completed_lines\": 4,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    },\n",
      "    \"rouge\": {\n",
      "        \"status\": \"Completed\",\n",
      "        \"duration\": \"0:00:01.029718\",\n",
      "        \"completed_lines\": 4,\n",
      "        \"failed_lines\": 0,\n",
      "        \"log_path\": null\n",
      "    }\n",
      "}\n",
      "\n",
      "====================================================\n",
      "\n"
     ]
    },
    {
     "ename": "EvaluationException",
     "evalue": "(UserError) Failed to upload evaluation run to the cloud due to insufficient permission to access the storage. Please ensure that the necessary access rights are granted.\nVisit https://aka.ms/azsdk/python/evaluation/remotetracking/troubleshoot to troubleshoot this issue.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/azure/ai/evaluation/_evaluate/_eval_run.py:447\u001b[0m, in \u001b[0;36mEvalRun.log_artifact\u001b[0;34m(self, artifact_folder, artifact_name)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(local, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m--> 447\u001b[0m             blob_client\u001b[38;5;241m.\u001b[39mupload_blob(fp, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HttpResponseError \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/azure/core/tracing/decorator.py:119\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/azure/storage/blob/_blob_client.py:765\u001b[0m, in \u001b[0;36mBlobClient.upload_blob\u001b[0;34m(self, data, blob_type, length, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blob_type \u001b[38;5;241m==\u001b[39m BlobType\u001b[38;5;241m.\u001b[39mBlockBlob:\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m upload_block_blob(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blob_type \u001b[38;5;241m==\u001b[39m BlobType\u001b[38;5;241m.\u001b[39mPageBlob:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/azure/storage/blob/_upload_helpers.py:195\u001b[0m, in \u001b[0;36mupload_block_blob\u001b[0;34m(client, data, stream, length, overwrite, headers, validate_content, max_concurrency, blob_settings, encryption_options, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     process_storage_error(error)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ResourceModifiedError \u001b[38;5;28;01mas\u001b[39;00m mod_error:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/azure/storage/blob/_shared/response_handlers.py:184\u001b[0m, in \u001b[0;36mprocess_storage_error\u001b[0;34m(storage_error)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# `from None` prevents us from double printing the exception (suppresses generated layer error context)\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     exec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise error from None\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \u001b[38;5;66;03m# pylint: disable=exec-used # nosec\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "\u001b[0;31mHttpResponseError\u001b[0m: Key based authentication is not permitted on this storage account.\nRequestId:dc7a4b74-001e-0002-0e66-42c541000000\nTime:2025-10-21T08:42:54.1484679Z\nErrorCode:KeyBasedAuthenticationNotPermitted\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>KeyBasedAuthenticationNotPermitted</Code><Message>Key based authentication is not permitted on this storage account.\nRequestId:dc7a4b74-001e-0002-0e66-42c541000000\nTime:2025-10-21T08:42:54.1484679Z</Message></Error>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mEvaluationException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m randomNum \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1111\u001b[39m, \u001b[38;5;241m9999\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m result \u001b[38;5;241m=\u001b[39m evaluate(\n\u001b[1;32m     35\u001b[0m     azure_ai_project\u001b[38;5;241m=\u001b[39mazure_ai_project, \n\u001b[1;32m     36\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai_data.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m     evaluation_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNLP-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model\u001b[38;5;241m.\u001b[39mtitle() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Run-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(randomNum),\n\u001b[1;32m     38\u001b[0m     target \u001b[38;5;241m=\u001b[39m ModelEndpoints(env_var, model),\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m     evaluators\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m\"\u001b[39m: BleuScoreEvaluator(),\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgleu\u001b[39m\u001b[38;5;124m\"\u001b[39m: GleuScoreEvaluator(),\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeteor\u001b[39m\u001b[38;5;124m\"\u001b[39m: MeteorScoreEvaluator(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3.0\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouge\u001b[39m\u001b[38;5;124m\"\u001b[39m: RougeScoreEvaluator(rouge_type\u001b[38;5;241m=\u001b[39mRougeType\u001b[38;5;241m.\u001b[39mROUGE_1),\n\u001b[1;32m     45\u001b[0m     },\n\u001b[1;32m     46\u001b[0m     evaluator_config\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbleu\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     48\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     49\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{data.ground_truth}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     50\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{target.response}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     51\u001b[0m         },\n\u001b[1;32m     52\u001b[0m     }\n\u001b[1;32m     53\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:839\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(data, evaluators, evaluation_name, target, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, tags, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EvaluationException):\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EvaluationException(\n\u001b[1;32m    833\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    834\u001b[0m         target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mEVALUATE,\n\u001b[1;32m    835\u001b[0m         category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mFAILED_EXECUTION,\n\u001b[1;32m    836\u001b[0m         blame\u001b[38;5;241m=\u001b[39mErrorBlame\u001b[38;5;241m.\u001b[39mSYSTEM_ERROR,\n\u001b[1;32m    837\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 839\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:796\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(data, evaluators, evaluation_name, target, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, tags, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m     user_agent: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m UserAgentSingleton()\u001b[38;5;241m.\u001b[39madd_useragent_product(user_agent) \u001b[38;5;28;01mif\u001b[39;00m user_agent \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext():\n\u001b[0;32m--> 796\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate(\n\u001b[1;32m    797\u001b[0m             evaluation_name\u001b[38;5;241m=\u001b[39mevaluation_name,\n\u001b[1;32m    798\u001b[0m             target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m    799\u001b[0m             data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    800\u001b[0m             evaluators_and_graders\u001b[38;5;241m=\u001b[39mevaluators,\n\u001b[1;32m    801\u001b[0m             evaluator_config\u001b[38;5;241m=\u001b[39mevaluator_config,\n\u001b[1;32m    802\u001b[0m             azure_ai_project\u001b[38;5;241m=\u001b[39mazure_ai_project,\n\u001b[1;32m    803\u001b[0m             output_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[1;32m    804\u001b[0m             fail_on_evaluator_errors\u001b[38;5;241m=\u001b[39mfail_on_evaluator_errors,\n\u001b[1;32m    805\u001b[0m             tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    806\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    807\u001b[0m         )\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;66;03m# Handle multiprocess bootstrap error\u001b[39;00m\n\u001b[1;32m    810\u001b[0m     bootstrap_error \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn attempt has been made to start a new process before the\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent process has finished its bootstrapping phase.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    813\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:978\u001b[0m, in \u001b[0;36m_evaluate\u001b[0;34m(evaluators_and_graders, evaluation_name, target, data, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, tags, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m     studio_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trace_destination:\n\u001b[0;32m--> 978\u001b[0m         studio_url \u001b[38;5;241m=\u001b[39m _log_metrics_and_instance_results(\n\u001b[1;32m    979\u001b[0m             metrics, results_df, trace_destination, \u001b[38;5;28;01mNone\u001b[39;00m, evaluation_name, name_map, tags\u001b[38;5;241m=\u001b[39mtags, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    980\u001b[0m         )\n\u001b[1;32m    982\u001b[0m result_df_dict \u001b[38;5;241m=\u001b[39m results_df\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    983\u001b[0m result: EvaluationResult \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m: result_df_dict, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudio_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: studio_url}  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/azure/ai/evaluation/_evaluate/_utils.py:269\u001b[0m, in \u001b[0;36m_log_metrics_and_instance_results\u001b[0;34m(metrics, instance_results, trace_destination, run, evaluation_name, name_map, tags, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(tmp_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mDefaultOpenEncoding\u001b[38;5;241m.\u001b[39mWRITE) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    267\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(instance_results\u001b[38;5;241m.\u001b[39mto_json(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m--> 269\u001b[0m ev_run\u001b[38;5;241m.\u001b[39mlog_artifact(tmpdir, artifact_name)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# Using mlflow to create a dummy run since once created via PF show traces of dummy run in UI.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Those traces can be confusing.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# adding these properties to avoid showing traces if a dummy run is created.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# We are doing that only for the pure evaluation runs.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/azure/ai/evaluation/_evaluate/_eval_run.py:454\u001b[0m, in \u001b[0;36mEvalRun.log_artifact\u001b[0;34m(self, artifact_folder, artifact_name)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m    450\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    451\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to upload evaluation run to the cloud due to insufficient permission to access the storage.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please ensure that the necessary access rights are granted.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         )\n\u001b[0;32m--> 454\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EvaluationException(\n\u001b[1;32m    455\u001b[0m             message\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[1;32m    456\u001b[0m             target\u001b[38;5;241m=\u001b[39mErrorTarget\u001b[38;5;241m.\u001b[39mEVAL_RUN,\n\u001b[1;32m    457\u001b[0m             category\u001b[38;5;241m=\u001b[39mErrorCategory\u001b[38;5;241m.\u001b[39mFAILED_REMOTE_TRACKING,\n\u001b[1;32m    458\u001b[0m             blame\u001b[38;5;241m=\u001b[39mErrorBlame\u001b[38;5;241m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    459\u001b[0m             tsg_link\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://aka.ms/azsdk/python/evaluation/remotetracking/troubleshoot\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    460\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    464\u001b[0m \u001b[38;5;66;03m# To show artifact in UI we will need to register it. If it is a promptflow run,\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# we are rewriting already registered artifact and need to skip this step.\u001b[39;00m\n",
      "\u001b[0;31mEvaluationException\u001b[0m: (UserError) Failed to upload evaluation run to the cloud due to insufficient permission to access the storage. Please ensure that the necessary access rights are granted.\nVisit https://aka.ms/azsdk/python/evaluation/remotetracking/troubleshoot to troubleshoot this issue."
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import evaluate, BleuScoreEvaluator, GleuScoreEvaluator, MeteorScoreEvaluator, RougeScoreEvaluator, RougeType\n",
    "import random\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "from target_nlp_api.target_nlp_api import ModelEndpoints\n",
    "\n",
    "# Re-initialize env_var with FULL endpoint URLs including deployment names\n",
    "env_var = { \n",
    "    \"gpt-35-turbo\": {\n",
    "        \"endpoint\": os.environ.get(\"AZURE_OPENAI_GPT35_ENDPOINT\") + \"openai/deployments/\" + os.environ.get(\"AZURE_OPENAI_GPT35_DEPLOYMENT\") + \"/chat/completions?api-version=2024-02-15-preview\",\n",
    "        \"key\": os.environ.get(\"AZURE_OPENAI_GPT35_API_KEY\"),\n",
    "    },\n",
    "    \"gpt-4\": {\n",
    "        \"endpoint\": os.environ.get(\"AZURE_OPENAI_GPT4_ENDPOINT\") + \"openai/deployments/\" + os.environ.get(\"AZURE_OPENAI_GPT4_DEPLOYMENT\") + \"/chat/completions?api-version=2024-02-15-preview\",\n",
    "        \"key\": os.environ.get(\"AZURE_OPENAI_GPT4_API_KEY\"),\n",
    "    },\n",
    "    \"gpt-4o\": {\n",
    "        \"endpoint\": os.environ.get(\"AZURE_OPENAI_GPT4o_ENDPOINT\") + \"openai/deployments/\" + os.environ.get(\"AZURE_OPENAI_GPT4o_DEPLOYMENT\") + \"/chat/completions?api-version=2024-02-15-preview\",\n",
    "        \"key\": os.environ.get(\"AZURE_OPENAI_GPT4o_API_KEY\"),\n",
    "    },\n",
    "    \"gpt-4o-mini\" : { \n",
    "        \"endpoint\" : os.environ.get(\"AZURE_OPENAI_GPT4o_ENDPOINT\") + \"openai/deployments/\" + os.environ.get(\"AZURE_OPENAI_GPT4o_DEPLOYMENT\") + \"/chat/completions?api-version=2024-02-15-preview\",\n",
    "        \"key\" : os.environ.get(\"AZURE_OPENAI_GPT4o_API_KEY\"), \n",
    "    },    \n",
    "}\n",
    "\n",
    "models = [\"gpt-35-turbo\",\"gpt-4\",\"gpt-4o\",\"gpt-4o-mini\"]\n",
    "\n",
    "for model in models:\n",
    "    print(\" Evaluating NLP metrics - \", model)\n",
    "    print(\"-----------------------------------\")\n",
    "    randomNum = random.randint(1111, 9999)\n",
    "    result = evaluate(\n",
    "        #azure_ai_project=azure_ai_project, \n",
    "        data=\"ai_data.jsonl\",\n",
    "        evaluation_name = \"NLP-\" + model.title() + \"_Run-\" + str(randomNum),\n",
    "        target = ModelEndpoints(env_var, model),\n",
    "\n",
    "        evaluators={\n",
    "            \"bleu\": BleuScoreEvaluator(),\n",
    "            \"gleu\": GleuScoreEvaluator(),\n",
    "            \"meteor\": MeteorScoreEvaluator(alpha=0.9, beta=3.0, gamma=0.5),\n",
    "            \"rouge\": RougeScoreEvaluator(rouge_type=RougeType.ROUGE_1),\n",
    "        },\n",
    "        evaluator_config={\n",
    "            \"bleu\": {\n",
    "                \"column_mapping\": {\n",
    "                    \"ground_truth\": \"${data.ground_truth}\",\n",
    "                    \"response\": \"${target.response}\"}\n",
    "            },\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the results, Alternatively you can view the results in AI Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1733832746266
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(result)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
